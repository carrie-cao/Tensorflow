{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uBTqR3nacj0e",
    "outputId": "4c0bd183-e424-429a-9fba-ceb841c06888"
   },
   "outputs": [],
   "source": [
    "#Artificial Neural Network basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx"
   },
   "outputs": [],
   "source": [
    "#data processing\n",
    "dataset = pd.read_excel('sample.xlsx')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFATpzsUAkLL"
   },
   "outputs": [],
   "source": [
    "#Initializing Model\n",
    "ann = tf.keras.models.Sequential()\n",
    "#Adding the input layer & the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "#Adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "#Adding the output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "IA0yApEmBG1X",
    "outputId": "cb981e1f-9204-4a2a-fece-9d66a6919189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "256/256 [==============================] - 0s 828us/step - loss: 229098.7812\n",
      "Epoch 2/100\n",
      "256/256 [==============================] - 0s 695us/step - loss: 206395.8750\n",
      "Epoch 3/100\n",
      "256/256 [==============================] - 0s 678us/step - loss: 206125.7188\n",
      "Epoch 4/100\n",
      "256/256 [==============================] - 0s 695us/step - loss: 205893.2031\n",
      "Epoch 5/100\n",
      "256/256 [==============================] - 0s 691us/step - loss: 205662.2812\n",
      "Epoch 6/100\n",
      "256/256 [==============================] - 0s 697us/step - loss: 205431.5156\n",
      "Epoch 7/100\n",
      "256/256 [==============================] - 0s 688us/step - loss: 205200.7500\n",
      "Epoch 8/100\n",
      "256/256 [==============================] - 0s 691us/step - loss: 204969.9688\n",
      "Epoch 9/100\n",
      "256/256 [==============================] - 0s 789us/step - loss: 204739.2344\n",
      "Epoch 10/100\n",
      "256/256 [==============================] - 0s 697us/step - loss: 204508.5625\n",
      "Epoch 11/100\n",
      "256/256 [==============================] - 0s 700us/step - loss: 204277.8594\n",
      "Epoch 12/100\n",
      "256/256 [==============================] - 0s 701us/step - loss: 204047.4062\n",
      "Epoch 13/100\n",
      "256/256 [==============================] - 0s 701us/step - loss: 203816.9844\n",
      "Epoch 14/100\n",
      "256/256 [==============================] - 0s 698us/step - loss: 203586.7031\n",
      "Epoch 15/100\n",
      "256/256 [==============================] - 0s 740us/step - loss: 203356.4219\n",
      "Epoch 16/100\n",
      "256/256 [==============================] - 0s 711us/step - loss: 203126.2656\n",
      "Epoch 17/100\n",
      "256/256 [==============================] - 0s 693us/step - loss: 202896.2500\n",
      "Epoch 18/100\n",
      "256/256 [==============================] - 0s 697us/step - loss: 202666.4219\n",
      "Epoch 19/100\n",
      "256/256 [==============================] - 0s 701us/step - loss: 202436.7656\n",
      "Epoch 20/100\n",
      "256/256 [==============================] - 0s 716us/step - loss: 202207.1719\n",
      "Epoch 21/100\n",
      "256/256 [==============================] - 0s 736us/step - loss: 201977.5469\n",
      "Epoch 22/100\n",
      "256/256 [==============================] - 0s 745us/step - loss: 201748.2344\n",
      "Epoch 23/100\n",
      "256/256 [==============================] - 0s 710us/step - loss: 201519.0781\n",
      "Epoch 24/100\n",
      "256/256 [==============================] - 0s 751us/step - loss: 201289.8281\n",
      "Epoch 25/100\n",
      "256/256 [==============================] - ETA: 0s - loss: 201108.70 - 0s 703us/step - loss: 201060.8438\n",
      "Epoch 26/100\n",
      "256/256 [==============================] - 0s 748us/step - loss: 200832.0625\n",
      "Epoch 27/100\n",
      "256/256 [==============================] - 0s 742us/step - loss: 200603.2500\n",
      "Epoch 28/100\n",
      "256/256 [==============================] - 0s 741us/step - loss: 200374.7812\n",
      "Epoch 29/100\n",
      "256/256 [==============================] - 0s 741us/step - loss: 200146.2500\n",
      "Epoch 30/100\n",
      "256/256 [==============================] - 0s 719us/step - loss: 199917.9688\n",
      "Epoch 31/100\n",
      "256/256 [==============================] - 0s 718us/step - loss: 199689.7969\n",
      "Epoch 32/100\n",
      "256/256 [==============================] - 0s 707us/step - loss: 199461.8281\n",
      "Epoch 33/100\n",
      "256/256 [==============================] - 0s 708us/step - loss: 199233.8438\n",
      "Epoch 34/100\n",
      "256/256 [==============================] - 0s 715us/step - loss: 199006.0469\n",
      "Epoch 35/100\n",
      "256/256 [==============================] - 0s 706us/step - loss: 198778.3750\n",
      "Epoch 36/100\n",
      "256/256 [==============================] - ETA: 0s - loss: 198668.43 - 0s 695us/step - loss: 198550.8281\n",
      "Epoch 37/100\n",
      "256/256 [==============================] - 0s 705us/step - loss: 198323.4531\n",
      "Epoch 38/100\n",
      "256/256 [==============================] - 0s 716us/step - loss: 198096.1250\n",
      "Epoch 39/100\n",
      "256/256 [==============================] - 0s 707us/step - loss: 197869.0312\n",
      "Epoch 40/100\n",
      "256/256 [==============================] - 0s 712us/step - loss: 197642.0312\n",
      "Epoch 41/100\n",
      "256/256 [==============================] - 0s 732us/step - loss: 197415.2031\n",
      "Epoch 42/100\n",
      "256/256 [==============================] - 0s 755us/step - loss: 197188.4219\n",
      "Epoch 43/100\n",
      "256/256 [==============================] - 0s 745us/step - loss: 196961.8906\n",
      "Epoch 44/100\n",
      "256/256 [==============================] - 0s 722us/step - loss: 196735.3750\n",
      "Epoch 45/100\n",
      "256/256 [==============================] - 0s 724us/step - loss: 196509.0312\n",
      "Epoch 46/100\n",
      "256/256 [==============================] - 0s 721us/step - loss: 196282.7188\n",
      "Epoch 47/100\n",
      "256/256 [==============================] - 0s 804us/step - loss: 196056.6562\n",
      "Epoch 48/100\n",
      "256/256 [==============================] - 0s 702us/step - loss: 195830.7031\n",
      "Epoch 49/100\n",
      "256/256 [==============================] - 0s 686us/step - loss: 195604.9531\n",
      "Epoch 50/100\n",
      "256/256 [==============================] - 0s 720us/step - loss: 195379.2500\n",
      "Epoch 51/100\n",
      "256/256 [==============================] - 0s 694us/step - loss: 195153.6094\n",
      "Epoch 52/100\n",
      "256/256 [==============================] - 0s 703us/step - loss: 194928.2344\n",
      "Epoch 53/100\n",
      "256/256 [==============================] - 0s 708us/step - loss: 194702.8438\n",
      "Epoch 54/100\n",
      "256/256 [==============================] - 0s 692us/step - loss: 194477.71880s - loss: 194575.\n",
      "Epoch 55/100\n",
      "256/256 [==============================] - 0s 682us/step - loss: 194252.5938\n",
      "Epoch 56/100\n",
      "256/256 [==============================] - 0s 707us/step - loss: 194027.7188\n",
      "Epoch 57/100\n",
      "256/256 [==============================] - 0s 680us/step - loss: 193802.9531\n",
      "Epoch 58/100\n",
      "256/256 [==============================] - 0s 714us/step - loss: 193578.2969\n",
      "Epoch 59/100\n",
      "256/256 [==============================] - 0s 701us/step - loss: 193353.6875\n",
      "Epoch 60/100\n",
      "256/256 [==============================] - 0s 691us/step - loss: 193129.4219\n",
      "Epoch 61/100\n",
      "256/256 [==============================] - 0s 702us/step - loss: 192905.0781\n",
      "Epoch 62/100\n",
      "256/256 [==============================] - 0s 704us/step - loss: 192680.9688\n",
      "Epoch 63/100\n",
      "256/256 [==============================] - 0s 711us/step - loss: 192456.9062\n",
      "Epoch 64/100\n",
      "256/256 [==============================] - 0s 741us/step - loss: 192233.1406\n",
      "Epoch 65/100\n",
      "256/256 [==============================] - 0s 702us/step - loss: 192009.4219\n",
      "Epoch 66/100\n",
      "256/256 [==============================] - 0s 713us/step - loss: 191785.8125\n",
      "Epoch 67/100\n",
      "256/256 [==============================] - 0s 706us/step - loss: 191562.2500\n",
      "Epoch 68/100\n",
      "256/256 [==============================] - 0s 699us/step - loss: 191338.9844\n",
      "Epoch 69/100\n",
      "256/256 [==============================] - 0s 698us/step - loss: 191115.7188\n",
      "Epoch 70/100\n",
      "256/256 [==============================] - 0s 699us/step - loss: 190892.7031\n",
      "Epoch 71/100\n",
      "256/256 [==============================] - 0s 679us/step - loss: 190669.6406\n",
      "Epoch 72/100\n",
      "256/256 [==============================] - 0s 682us/step - loss: 190446.9062\n",
      "Epoch 73/100\n",
      "256/256 [==============================] - 0s 714us/step - loss: 190224.2344\n",
      "Epoch 74/100\n",
      "256/256 [==============================] - 0s 684us/step - loss: 190001.5781\n",
      "Epoch 75/100\n",
      "256/256 [==============================] - ETA: 0s - loss: 189847.28 - 0s 705us/step - loss: 189779.1406\n",
      "Epoch 76/100\n",
      "256/256 [==============================] - 0s 707us/step - loss: 189556.8594\n",
      "Epoch 77/100\n",
      "256/256 [==============================] - 0s 692us/step - loss: 189334.7344\n",
      "Epoch 78/100\n",
      "256/256 [==============================] - 0s 705us/step - loss: 189112.6875\n",
      "Epoch 79/100\n",
      "256/256 [==============================] - 0s 707us/step - loss: 188890.8125\n",
      "Epoch 80/100\n",
      "256/256 [==============================] - 0s 698us/step - loss: 188668.9531\n",
      "Epoch 81/100\n",
      "256/256 [==============================] - 0s 691us/step - loss: 188447.3750\n",
      "Epoch 82/100\n",
      "256/256 [==============================] - 0s 697us/step - loss: 188225.8906\n",
      "Epoch 83/100\n",
      "256/256 [==============================] - 0s 706us/step - loss: 188004.4844\n",
      "Epoch 84/100\n",
      "256/256 [==============================] - 0s 691us/step - loss: 187783.2344\n",
      "Epoch 85/100\n",
      "256/256 [==============================] - 0s 703us/step - loss: 187562.0938\n",
      "Epoch 86/100\n",
      "256/256 [==============================] - 0s 684us/step - loss: 187341.1562\n",
      "Epoch 87/100\n",
      "256/256 [==============================] - 0s 714us/step - loss: 187120.2656\n",
      "Epoch 88/100\n",
      "256/256 [==============================] - 0s 702us/step - loss: 186899.4688\n",
      "Epoch 89/100\n",
      "256/256 [==============================] - 0s 692us/step - loss: 186678.9375\n",
      "Epoch 90/100\n",
      "256/256 [==============================] - 0s 677us/step - loss: 186458.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "256/256 [==============================] - 0s 696us/step - loss: 186238.0625\n",
      "Epoch 92/100\n",
      "256/256 [==============================] - 0s 696us/step - loss: 186017.8750\n",
      "Epoch 93/100\n",
      "256/256 [==============================] - 0s 704us/step - loss: 185797.7656\n",
      "Epoch 94/100\n",
      "256/256 [==============================] - 0s 697us/step - loss: 185577.8281\n",
      "Epoch 95/100\n",
      "256/256 [==============================] - ETA: 0s - loss: 185368.18 - 0s 696us/step - loss: 185358.1094\n",
      "Epoch 96/100\n",
      "256/256 [==============================] - 0s 706us/step - loss: 185138.4531\n",
      "Epoch 97/100\n",
      "256/256 [==============================] - 0s 696us/step - loss: 184918.7500\n",
      "Epoch 98/100\n",
      "256/256 [==============================] - 0s 699us/step - loss: 184699.3906\n",
      "Epoch 99/100\n",
      "256/256 [==============================] - 0s 700us/step - loss: 184480.1875\n",
      "Epoch 100/100\n",
      "256/256 [==============================] - 0s 680us/step - loss: 184260.9219\n",
      "[[ 25.51 431.23]\n",
      " [ 25.51 460.01]\n",
      " [ 25.51 461.14]\n",
      " ...\n",
      " [ 25.51 473.26]\n",
      " [ 25.51 438.  ]\n",
      " [ 25.51 463.28]]\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "#Compiling \n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "ann.fit(X_train, y_train, batch_size = 30, epochs = 100)\n",
    "# Predicting \n",
    "y_pred = ann.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
